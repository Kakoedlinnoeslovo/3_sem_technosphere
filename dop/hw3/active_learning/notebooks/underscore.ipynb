{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x[1]*x[6] + x[8]/x[9]*np.sqrt(x[6]/x[7]) + (np.pi)*np.sqrt(x[2]) + 1/np.sin(x[3]) + np.log(x[2]+x[4]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_COUNT = 2000\n",
    "COUNT_TO_ADD = 50\n",
    "TOT_SIZE = 1000000\n",
    "PATH_TO_DATA = \"all/public.data\"\n",
    "TARGET = np.zeros(TOT_SIZE)\n",
    "list_of_initial_index = []\n",
    "PFR = RandomForestRegressor(n_estimators = 150, n_jobs = -1)\n",
    "BAGG = BaggingRegressor(n_estimators = 150, n_jobs = -1)\n",
    "GDR = GradientBoostingRegressor(n_estimators =150, learning_rate = 0.075)\n",
    "ADA = AdaBoostRegressor(n_estimators = 150, learning_rate = 0.01)\n",
    "models = [PFR, BAGG, GDR, ADA]\n",
    "sample = pd.read_csv(\"all/public.sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(PATH_TO_DATA, \n",
    "                   sep= \" \", \n",
    "                   names=[\"feature_{}\".format(i) for i in range(0, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.401877</td>\n",
       "      <td>3.943829</td>\n",
       "      <td>7.830992</td>\n",
       "      <td>7.984400</td>\n",
       "      <td>9.116474</td>\n",
       "      <td>1.975514</td>\n",
       "      <td>3.352228</td>\n",
       "      <td>7.682296</td>\n",
       "      <td>2.777747</td>\n",
       "      <td>5.539700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.773971</td>\n",
       "      <td>6.288709</td>\n",
       "      <td>3.647845</td>\n",
       "      <td>5.134009</td>\n",
       "      <td>9.522297</td>\n",
       "      <td>9.161951</td>\n",
       "      <td>6.357117</td>\n",
       "      <td>7.172969</td>\n",
       "      <td>1.416026</td>\n",
       "      <td>6.069689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.163006</td>\n",
       "      <td>2.428868</td>\n",
       "      <td>1.372316</td>\n",
       "      <td>8.041768</td>\n",
       "      <td>1.566791</td>\n",
       "      <td>4.009444</td>\n",
       "      <td>1.297904</td>\n",
       "      <td>1.088088</td>\n",
       "      <td>9.989245</td>\n",
       "      <td>2.182569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.129324</td>\n",
       "      <td>8.391122</td>\n",
       "      <td>6.126398</td>\n",
       "      <td>2.960316</td>\n",
       "      <td>6.375523</td>\n",
       "      <td>5.242872</td>\n",
       "      <td>4.935830</td>\n",
       "      <td>9.727750</td>\n",
       "      <td>2.925168</td>\n",
       "      <td>7.713577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.267450</td>\n",
       "      <td>7.699138</td>\n",
       "      <td>4.002286</td>\n",
       "      <td>8.915295</td>\n",
       "      <td>2.833147</td>\n",
       "      <td>3.524583</td>\n",
       "      <td>8.077245</td>\n",
       "      <td>9.190265</td>\n",
       "      <td>0.697553</td>\n",
       "      <td>9.493271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   8.401877   3.943829   7.830992   7.984400   9.116474   1.975514   \n",
       "1   4.773971   6.288709   3.647845   5.134009   9.522297   9.161951   \n",
       "2   0.163006   2.428868   1.372316   8.041768   1.566791   4.009444   \n",
       "3   5.129324   8.391122   6.126398   2.960316   6.375523   5.242872   \n",
       "4   5.267450   7.699138   4.002286   8.915295   2.833147   3.524583   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  \n",
       "0   3.352228   7.682296   2.777747   5.539700  \n",
       "1   6.357117   7.172969   1.416026   6.069689  \n",
       "2   1.297904   1.088088   9.989245   2.182569  \n",
       "3   4.935830   9.727750   2.925168   7.713577  \n",
       "4   8.077245   9.190265   0.697553   9.493271  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First init 2000 points to start active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_initial_index = []\n",
    "\n",
    "for _ in range(INIT_COUNT):\n",
    "    now_ind = np.random.randint(TOT_SIZE)\n",
    "    list_of_initial_index.append(now_ind)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(INIT_COUNT):\n",
    "    temp_pont = np.array(data.iloc[list_of_initial_index[i]])\n",
    "    value = func(temp_pont)\n",
    "    TARGET[list_of_initial_index[i]] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of training data: 1999\n"
     ]
    }
   ],
   "source": [
    "print(\"Len of training data: {}\".\n",
    "      format(len(np.unique(list_of_initial_index))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "inde = 0\n",
    "\n",
    "new_final_ind = np.unique(list_of_initial_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_target(new_ind, target):\n",
    "    for ind in new_ind:\n",
    "        temp_pont = np.array(data.iloc[ind])\n",
    "        value = func(temp_pont)\n",
    "        target[ind] = value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_final_ind = list(new_final_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:02<36:04,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 0 step is: 2049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [04:00<35:38,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 100 step is: 7049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [09:58<39:38,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 200 step is: 12049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [17:28<40:35,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 300 step is: 17049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [27:17<40:46,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 400 step is: 22049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 472/1000 [35:57<40:13,  4.57s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-6d082af3c25d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#print(\"Fitting algorithm on errors\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mGDR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mpred_errs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGDR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mpred_errs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_final_ind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    796\u001b[0m                 loss.update_terminal_regions(tree.tree_, X, y, residual, y_pred,\n\u001b[1;32m    797\u001b[0m                                              \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                                              self.learning_rate, k=k)\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;31m# add tree to ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mupdate_terminal_regions\u001b[0;34m(self, tree, X, y, residual, y_pred, sample_weight, sample_mask, learning_rate, k)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \"\"\"\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# update predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "for KDP in tqdm(range(1000)):\n",
    "    inde+=1\n",
    "    #Get the spread of predictions of the algorithm committee.\n",
    "    \n",
    "    #print(\"Len of training data: {}\".\n",
    "      #format(len(new_final_ind))\n",
    "    \n",
    "    X_train_new = data.iloc[new_final_ind]\n",
    "    y_train_new = TARGET[new_final_ind]\n",
    "    \n",
    "    #print(\"Fitting algorithm\")\n",
    "    GDR.fit(X_train_new, y_train_new)\n",
    "    pred = GDR.predict(X_train_new)\n",
    "    \n",
    "    #Looking for points with max-size errors\n",
    "    \n",
    "    err = np.abs(pred - y_train_new)\n",
    "    #print(\"Fitting algorithm on errors\")\n",
    "   \n",
    "    GDR.fit(X_train_new, err)\n",
    "    pred_errs = np.abs(GDR.predict(data))\n",
    "    pred_errs[new_final_ind] = 0 \n",
    "    \n",
    "    #print(\"Getting points with max errors\")\n",
    "    new_ind = pred_errs.argsort()[::-1][:COUNT_TO_ADD]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(\"Getting new target values\")\n",
    "    \n",
    "    fill_target(new_ind, TARGET)\n",
    "    new_final_ind = list(np.unique(new_final_ind + list(new_ind)))\n",
    "    \n",
    "            \n",
    "            \n",
    "    if (KDP % 100 == 0):\n",
    "        print(\"Size of TARGET on {} step is: {}\".\\\n",
    "              format(KDP, len(TARGET[TARGET!=0])))\n",
    "        \n",
    "        print(\"Making submit\")\n",
    "        \n",
    "        sample.Expected = TARGET\n",
    "\n",
    "        sample.to_csv(\"sub_{}\".format(KDP), index = False)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"all/public.sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.Expected = TARGET\n",
    "\n",
    "sample.to_csv(\"sub_4\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
